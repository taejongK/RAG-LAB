{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PDF2Markdown\n",
    "\n",
    "- pymupdf4llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pymupdf4llm\n",
    "# FILE_PATH = \"/home/taejong_kim/workspace/rag-lab/database/BA_사용메뉴얼_분석가.pdf\"\n",
    "# IMG_CONTENT_PATH = \"/home/taejong_kim/workspace/rag-lab/database/image\"\n",
    "\n",
    "# md_text = pymupdf4llm.to_markdown(\n",
    "#     FILE_PATH, write_images=True, image_path=IMG_CONTENT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import re\n",
    "\n",
    "# splited_markdonw = [item for item in re.split(\n",
    "#     r'(?<!##)##(?!##)', md_text) if item != '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain.schema import Document\n",
    "\n",
    "\n",
    "# def extract_images_and_create_documents(text):\n",
    "#     \"\"\"\n",
    "#     Markdown 텍스트에서 ![]() 형식의 이미지를 추출하고, \n",
    "#     본문과 이미지 리스트를 LangChain Document 객체로 변환\n",
    "#     \"\"\"\n",
    "#     # 이미지 패턴 탐색 (예: ![alt text](image_url))\n",
    "#     image_pattern = re.compile(r'!\\[.*?\\]\\((.*?)\\)')\n",
    "\n",
    "#     # 이미지 리스트 추출\n",
    "#     images = image_pattern.findall(text)\n",
    "\n",
    "#     # 본문에서 이미지 태그 제거\n",
    "#     cleaned_text = image_pattern.sub('', text).strip()\n",
    "\n",
    "#     # LangChain Document 생성\n",
    "#     return Document(page_content=cleaned_text, metadata={\"images\": images})\n",
    "\n",
    "\n",
    "# docs4md = []\n",
    "# for md in splited_markdonw:\n",
    "#     doc = extract_images_and_create_documents(md)\n",
    "#     docs4md.append(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vector Store\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import pickle\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HuggingFace\n",
    "- model = 'jhgan/ko-sroberta-multitask'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hf = HuggingFaceEmbeddings(\n",
    "#     model_name='jhgan/ko-sroberta-multitask')  # embedding model\n",
    "\n",
    "# vectorstore = FAISS.from_documents(docs4md, embedding=hf)  # vector store\n",
    "# retriever = vectorstore.retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "VECTORSTORE_PATH = \"/home/taejong_kim/workspace/rag-lab/database/vector_store\"\n",
    "EMBEDDING_MODEL_PATH = \"/home/taejong_kim/workspace/rag-lab/database/embedding_model\" + \\\n",
    "    \"/hf_embedding_model01.pkl\"\n",
    "\n",
    "# vectorstore.save_local(VECTORSTORE_PATH)\n",
    "\n",
    "# with open(EMBEDDING_MODEL_PATH, \"wb\") as f:\n",
    "#     pickle.dump(hf, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "검색 결과:  목록\n",
      "\n",
      "1. BRIQUE Analytics에서 다중처리의 의미\n",
      "\n",
      "2. 알고리즘 작성\n",
      "\n",
      "3. 분석플로우 작성 및 실행\n"
     ]
    }
   ],
   "source": [
    "# 1. 저장된 임베딩 모델 불러오기\n",
    "\n",
    "with open(EMBEDDING_MODEL_PATH, \"rb\") as f:\n",
    "    embedding_model = pickle.load(f)\n",
    "\n",
    "# 2. 저장된 벡터스토어 불러오기\n",
    "vectorstore = FAISS.load_local(\n",
    "    VECTORSTORE_PATH, embedding_model, allow_dangerous_deserialization=True)\n",
    "\n",
    "\n",
    "# 3. 검색\n",
    "query = \"분석가\"\n",
    "results = vectorstore.similarity_search(query, top_k=5)\n",
    "\n",
    "print('검색 결과: ', results[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[], [], [], []]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_paths = [doc.metadata['images'] for doc in results]\n",
    "image_paths\n",
    "\n",
    "# results[1].metadata['images']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableLambda(itemgetter('분석가'))\n",
       "| VectorStoreRetriever(tags=['FAISS', 'HuggingFaceEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x7f987582fbf0>, search_kwargs={})\n",
       "| StrOutputParser()"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "itemgetter(query) | retriever | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc in retriever.get_relevant_documents(query, top_k=5):\n",
    "    img_path = doc.metadata[\"images\"]\n",
    "    if len(img_path) > 0:\n",
    "        for img in img_path:\n",
    "            print(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser, JsonOutputParser\n",
    "\n",
    "\n",
    "prompt = PromptTemplate.from_template(\n",
    "    \"\"\"\"You are a support agent. \n",
    "Please respond in the same language as the user's input. Detect the language they are using and reply naturally in that language while maintaining clarity and accuracy.\n",
    "\n",
    "If you don't know the answer, just say that you don't know. \n",
    "\n",
    "Use the following pieces of retrieved context to answer the question. \n",
    "\n",
    "#Question: \n",
    "{question} \n",
    "\n",
    "#Context: \n",
    "{context} \n",
    "\n",
    "#Answer:\"\"\"\n",
    ")\n",
    "\n",
    "# 언어 모델\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-pro-latest\")\n",
    "\n",
    "chain = (\n",
    "    {\n",
    "        \"context\": itemgetter(\"question\") | retriever,\n",
    "        \"question\": itemgetter(\"question\"),\n",
    "    }\n",
    "    | prompt\n",
    "    | llm\n",
    "    # | JsonOutputParser()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = {'question':'워크플로우 생성 방법'}\n",
    "answer = chain.invoke(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'content': '제공된 문서에는 워크플로우 생성 방법에 대한 자세한 설명은 나와 있지 않습니다. 워크플로우를 \"여는\" 방법이나 워크플로우의 \"실행 엔진 정보 조회\" 방법에 대한 내용은 있지만,  \"생성\" 방법에 대한 구체적인 내용은 없습니다.  더 자세한 정보를 원하시면 다른 문서를 참고하시거나, 워크플로우 관련 매뉴얼을 확인해 보시기 바랍니다.',\n",
       " 'additional_kwargs': {},\n",
       " 'response_metadata': {'prompt_feedback': {'block_reason': 0,\n",
       "   'safety_ratings': []},\n",
       "  'finish_reason': 'STOP',\n",
       "  'safety_ratings': []},\n",
       " 'type': 'ai',\n",
       " 'name': None,\n",
       " 'id': 'run-875dcbf5-8997-4b40-b40f-1b0cd99e33a8-0',\n",
       " 'example': False,\n",
       " 'tool_calls': [],\n",
       " 'invalid_tool_calls': [],\n",
       " 'usage_metadata': {'input_tokens': 772,\n",
       "  'output_tokens': 118,\n",
       "  'total_tokens': 890,\n",
       "  'input_token_details': {'cache_read': 0}}}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer.model_dump()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'워크플로우 생성 방법'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query['question']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/taejong_kim/workspace/rag-lab/database/image/BA_사용메뉴얼_분석가.pdf-172-0.png']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_list = []\n",
    "\n",
    "for doc in retriever.invoke(query['question']):\n",
    "    img_path = doc.metadata[\"images\"]\n",
    "    if len(img_path) > 0:\n",
    "        for img in img_path:\n",
    "            img_list.append(img)\n",
    "            \n",
    "img_list"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
